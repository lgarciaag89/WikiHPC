{
    "docs": [
        {
            "location": "/", 
            "text": "POL\u00cdTICAS DE USO DE LOS SERVICIOS DEL HPC DE LA UNIVERSIDAD DE LAS CIENCIAS INFORM\u00c1TICAS.\n\n\nIntroducci\u00f3n\n\n\nEl presente documento tiene como objetivo definir las pol\u00edticas de acceso de la infraestructura HPC UCI, as\u00ed como las pol\u00edticas de seguridad y uso de los recursos por parte de los investigadores que accedan al mismo. Las pol\u00edticas definidas en este documento ser\u00e1n revisadas peri\u00f3dicamente y cualquier cambio en las mismas, ser\u00e1 aprobado por la direcci\u00f3n de la universidad y trasmitido a toda la comunidad universitaria.\n\n\nObjetivo del HPC UCI\n\n\nProveer a la comunidad cient\u00edfica de la UCI, de una infraestructura de computaci\u00f3n de alto desempe\u00f1o (High Performance Computing, HPC), para el desarrollo y ejecuci\u00f3n de proyectos de investigaci\u00f3n que requieran alto procesamiento de datos.  \n\n\nPol\u00edticas de Uso\n\n\n\n\nEl uso del HPC UCI es libre para todos los miembros de la comunidad universitaria que requieran c\u00f3mputo de alto rendimiento en sus actividades de investigaci\u00f3n y estar\u00e1 regido por \u00e9stas \u201cPol\u00edticas de Uso\u201d.\n\n\nEl acceso al HPC se realizar\u00e1 a trav\u00e9s del protocolo Secure Shell (SSH) con los mecanismos de autenticaci\u00f3n usuario-contrase\u00f1a o llave p\u00fablica-llave privada. \n\n\nEl acceso de un investigador al HPC ser\u00e1 aprobado por    el \u201cComit\u00e9 de Administraci\u00f3n del HPC UCI\u201d y dicho investigador deber\u00e1 estar relacionado a un proyecto de investigaci\u00f3n de la Universidad en ejecuci\u00f3n. La autorizaci\u00f3n de acceso al HPC UCI y a los recursos obedecer\u00e1 a un proceso de an\u00e1lisis y evaluaci\u00f3n de las     necesidades que presenten los proyectos que requieran tiempo de c\u00f3mputo en el HPC.\n\n\nPor razones de seguridad, no se podr\u00e1 acceder v\u00eda SSH al sistema HPC UCI desde una computadora que se encuentre fuera de la red de datos UCI. Solo en casos excepcionales, se autorizar\u00e1 el ingreso de un usuario al HPC desde fuera de la Universidad a trav\u00e9s de este protocolo.\n\n\nA cada investigador autorizado a usar el sistema HPC UCI se le asignar\u00e1 un l\u00edmite de tiempo para cada trabajo de c\u00e1lculo. La asignaci\u00f3n del tiempo para cada c\u00e1lculo se determinar\u00e1 en base a las necesidades que tenga cada investigador.\n\n\nLos proyectos estar\u00e1n organizados por prioridad, siendo tarea del \u201cComit\u00e9 de Administraci\u00f3n del HPC UCI\u201d definir la prioridad    para cada proyecto. Esta prioridad define el orden y los recursos a utilizar en el HPC, siendo las tareas asociadas a proyectos con mayor prioridad las primeras en ser ejecutadas. La prioridad para cada proyecto depender\u00e1 del impacto de la investigaci\u00f3n o el fin de la misma y se definir\u00e1 como (alto, medio, bajo).\n\n\nPara la ejecuci\u00f3n de tareas en el HPC ser\u00e1n definidas diferentes colas de ejecuci\u00f3n configuradas con SLURMi. Cada proyecto ser\u00e1 asignado a una cola en dependencia de la importancia y el tiempo asignado. \n\n\nEl usuario deber\u00e1 ejecutar las tareas solamente en la cola (o las colas) que se le defina al proyecto al que est\u00e1 asociado. La ejecuci\u00f3n de tareas fuera de la cola definida no se realizar\u00e1, defini\u00e9ndose un ambiente interactivo en el caso de que el usuario necesite realizar pruebas pre-ejecuci\u00f3n.\n\n\nEl sistema HPC UCI es un cl\u00faster para c\u00f3mputo de alto rendimiento y no un equipo de almacenamiento, por lo que su espacio en disco es limitado. Considerando esto, es obligaci\u00f3n de cada usuario, eliminar los archivos que resulten de sus c\u00e1lculos de forma regular para evitar el mal funcionamiento del equipo.\n\n\nLa instalaci\u00f3n de cualquier programa, componente o librer\u00eda dentro del sistema HPC UCI deber\u00e1 ser aprobada por el \u201cComit\u00e9 de Administraci\u00f3n del HPC UCI\u201d.\n\n\nLas publicaciones resultantes (parciales o completas) de ejecuciones realizadas en el HPC UCI deber\u00e1n poner en Agradecimientos, que sus resultados o parte de ellos fueron obtenidos en el HPC UCI. Se recomienda poner: \u201cLos recursos computacionales utilizados en este trabajo fueron proporcionados por el Sistema de Alto Rendimiento de la Universidad de las Ciencias (UCI).\n\n\nTodos los usuarios del HPC UCI deber\u00e1n firmar un documento de aceptaci\u00f3n de estas Pol\u00edticas de Uso.", 
            "title": "Home"
        }, 
        {
            "location": "/#politicas-de-uso-de-los-servicios-del-hpc-de-la-universidad-de-las-ciencias-informaticas", 
            "text": "", 
            "title": "POL\u00cdTICAS DE USO DE LOS SERVICIOS DEL HPC DE LA UNIVERSIDAD DE LAS CIENCIAS INFORM\u00c1TICAS."
        }, 
        {
            "location": "/#introduccion", 
            "text": "El presente documento tiene como objetivo definir las pol\u00edticas de acceso de la infraestructura HPC UCI, as\u00ed como las pol\u00edticas de seguridad y uso de los recursos por parte de los investigadores que accedan al mismo. Las pol\u00edticas definidas en este documento ser\u00e1n revisadas peri\u00f3dicamente y cualquier cambio en las mismas, ser\u00e1 aprobado por la direcci\u00f3n de la universidad y trasmitido a toda la comunidad universitaria.", 
            "title": "Introducci\u00f3n"
        }, 
        {
            "location": "/#objetivo-del-hpc-uci", 
            "text": "Proveer a la comunidad cient\u00edfica de la UCI, de una infraestructura de computaci\u00f3n de alto desempe\u00f1o (High Performance Computing, HPC), para el desarrollo y ejecuci\u00f3n de proyectos de investigaci\u00f3n que requieran alto procesamiento de datos.", 
            "title": "Objetivo del HPC UCI"
        }, 
        {
            "location": "/#politicas-de-uso", 
            "text": "El uso del HPC UCI es libre para todos los miembros de la comunidad universitaria que requieran c\u00f3mputo de alto rendimiento en sus actividades de investigaci\u00f3n y estar\u00e1 regido por \u00e9stas \u201cPol\u00edticas de Uso\u201d.  El acceso al HPC se realizar\u00e1 a trav\u00e9s del protocolo Secure Shell (SSH) con los mecanismos de autenticaci\u00f3n usuario-contrase\u00f1a o llave p\u00fablica-llave privada.   El acceso de un investigador al HPC ser\u00e1 aprobado por    el \u201cComit\u00e9 de Administraci\u00f3n del HPC UCI\u201d y dicho investigador deber\u00e1 estar relacionado a un proyecto de investigaci\u00f3n de la Universidad en ejecuci\u00f3n. La autorizaci\u00f3n de acceso al HPC UCI y a los recursos obedecer\u00e1 a un proceso de an\u00e1lisis y evaluaci\u00f3n de las     necesidades que presenten los proyectos que requieran tiempo de c\u00f3mputo en el HPC.  Por razones de seguridad, no se podr\u00e1 acceder v\u00eda SSH al sistema HPC UCI desde una computadora que se encuentre fuera de la red de datos UCI. Solo en casos excepcionales, se autorizar\u00e1 el ingreso de un usuario al HPC desde fuera de la Universidad a trav\u00e9s de este protocolo.  A cada investigador autorizado a usar el sistema HPC UCI se le asignar\u00e1 un l\u00edmite de tiempo para cada trabajo de c\u00e1lculo. La asignaci\u00f3n del tiempo para cada c\u00e1lculo se determinar\u00e1 en base a las necesidades que tenga cada investigador.  Los proyectos estar\u00e1n organizados por prioridad, siendo tarea del \u201cComit\u00e9 de Administraci\u00f3n del HPC UCI\u201d definir la prioridad    para cada proyecto. Esta prioridad define el orden y los recursos a utilizar en el HPC, siendo las tareas asociadas a proyectos con mayor prioridad las primeras en ser ejecutadas. La prioridad para cada proyecto depender\u00e1 del impacto de la investigaci\u00f3n o el fin de la misma y se definir\u00e1 como (alto, medio, bajo).  Para la ejecuci\u00f3n de tareas en el HPC ser\u00e1n definidas diferentes colas de ejecuci\u00f3n configuradas con SLURMi. Cada proyecto ser\u00e1 asignado a una cola en dependencia de la importancia y el tiempo asignado.   El usuario deber\u00e1 ejecutar las tareas solamente en la cola (o las colas) que se le defina al proyecto al que est\u00e1 asociado. La ejecuci\u00f3n de tareas fuera de la cola definida no se realizar\u00e1, defini\u00e9ndose un ambiente interactivo en el caso de que el usuario necesite realizar pruebas pre-ejecuci\u00f3n.  El sistema HPC UCI es un cl\u00faster para c\u00f3mputo de alto rendimiento y no un equipo de almacenamiento, por lo que su espacio en disco es limitado. Considerando esto, es obligaci\u00f3n de cada usuario, eliminar los archivos que resulten de sus c\u00e1lculos de forma regular para evitar el mal funcionamiento del equipo.  La instalaci\u00f3n de cualquier programa, componente o librer\u00eda dentro del sistema HPC UCI deber\u00e1 ser aprobada por el \u201cComit\u00e9 de Administraci\u00f3n del HPC UCI\u201d.  Las publicaciones resultantes (parciales o completas) de ejecuciones realizadas en el HPC UCI deber\u00e1n poner en Agradecimientos, que sus resultados o parte de ellos fueron obtenidos en el HPC UCI. Se recomienda poner: \u201cLos recursos computacionales utilizados en este trabajo fueron proporcionados por el Sistema de Alto Rendimiento de la Universidad de las Ciencias (UCI).  Todos los usuarios del HPC UCI deber\u00e1n firmar un documento de aceptaci\u00f3n de estas Pol\u00edticas de Uso.", 
            "title": "Pol\u00edticas de Uso"
        }, 
        {
            "location": "/acceso/", 
            "text": "Acceso al servidor y transferencia de datos\n\n\nEl usuario deber\u00e1 iniciar sesi\u00f3n en el cluster a trav\u00e9s de un cliente ssh mediante el servidor de login utilizando usuario y contrase\u00f1a o un par llave p\u00fablica-llave privada. El software que necesitar\u00e1 usar en su sistema cliente depende de su sistema operativo:\n\n\nAcceso desde window\n\n\nSe puede abrir una sesi\u00f3n modo texto utilizando un cliente ssh como putty: \nftp uci\n,\nweb oficial\n.\n\n\nPara enviar datos y recibir datos desde el cluster se pueden utilizar:\n\n\n\n\n\n\nWinSCP: \nftp uci\n, \nweb oficial\n\n\n\n\n\n\nFileZilla: \nftp uci\n, \nweb oficial\n\n\n\n\n\n\nAcceso desde linux modo texto utilizando OpenSSH\n\n\nRequisitos:OpenSSH\n\n\nEn la mayor\u00eda de los casos un enlace en modo texto es suficiente para la ejecuci\u00f3n de las tareas. Para esto, se utiliza el comando \nssh\n:\n\n\n$ ssh \nusuario\n@\nip_nodo_login\n\n\n\n\nLa primera vez que se conecte al servidor de login, usted deber\u00e1 autenticar el nodo login, ejemplo: \n\n\nThe authenticity of host 'hostname (ip)' can't be established.ECDSA key fingerprint is SHA256:+795v7FnFcMGcwlok8eHxJN27XEVqg94Y0ROxZNz/Gs.Are you sure you want to continue connecting (yes/no)?\n\n\n\nPara enviar y recibir datos desde el cluster se puede auxiliar del comando \nscp\n:\n\n\n$ scp fichero_a_enviar usuario_remoto@hostremoto:/some/remote/directory/\n\n\n\nEnlaces de inter\u00e9s\n\n\n\n\nman scp\n\n\nman ssh\n \n\n\nAyuda scp\n\n\nAyuda ssh\n\n\nAyuda winscp\n\n\nAyuda putty", 
            "title": "Acceso y transferencias"
        }, 
        {
            "location": "/acceso/#acceso-al-servidor-y-transferencia-de-datos", 
            "text": "El usuario deber\u00e1 iniciar sesi\u00f3n en el cluster a trav\u00e9s de un cliente ssh mediante el servidor de login utilizando usuario y contrase\u00f1a o un par llave p\u00fablica-llave privada. El software que necesitar\u00e1 usar en su sistema cliente depende de su sistema operativo:", 
            "title": "Acceso al servidor y transferencia de datos"
        }, 
        {
            "location": "/acceso/#acceso-desde-window", 
            "text": "Se puede abrir una sesi\u00f3n modo texto utilizando un cliente ssh como putty:  ftp uci , web oficial .  Para enviar datos y recibir datos desde el cluster se pueden utilizar:    WinSCP:  ftp uci ,  web oficial    FileZilla:  ftp uci ,  web oficial", 
            "title": "Acceso desde window"
        }, 
        {
            "location": "/acceso/#acceso-desde-linux-modo-texto-utilizando-openssh", 
            "text": "Requisitos:OpenSSH  En la mayor\u00eda de los casos un enlace en modo texto es suficiente para la ejecuci\u00f3n de las tareas. Para esto, se utiliza el comando  ssh :  $ ssh  usuario @ ip_nodo_login   La primera vez que se conecte al servidor de login, usted deber\u00e1 autenticar el nodo login, ejemplo:   The authenticity of host 'hostname (ip)' can't be established.ECDSA key fingerprint is SHA256:+795v7FnFcMGcwlok8eHxJN27XEVqg94Y0ROxZNz/Gs.Are you sure you want to continue connecting (yes/no)?  Para enviar y recibir datos desde el cluster se puede auxiliar del comando  scp :  $ scp fichero_a_enviar usuario_remoto@hostremoto:/some/remote/directory/", 
            "title": "Acceso desde linux modo texto utilizando OpenSSH"
        }, 
        {
            "location": "/acceso/#enlaces-de-interes", 
            "text": "man scp  man ssh    Ayuda scp  Ayuda ssh  Ayuda winscp  Ayuda putty", 
            "title": "Enlaces de inter\u00e9s"
        }, 
        {
            "location": "/comandos/", 
            "text": "Ejecuci\u00f3n de tareas\n\n\nEl cluster cuenta con \nslurm\n como planificador de tareas.  El usuario tendr\u00e1 la oportunidad de ejecutar sus tareas en las diferentes colas de ejecuci\u00f3n, en dependencia del tiempo y los recursos necesarios para ejecutar la tarea.\n\n\nIntroducci\u00f3n\n\n\nLas tareas en el cluster ser\u00e1n atendidas por slurm. Para poder ejecutar una tarea normalmente un usuario debe preparar un script de ejecuci\u00f3n donde define la aplicaci\u00f3n que desea ejecutar, los juegos de entrada, la forma en que obtendr\u00e1 la salida y los recursos que necesita para ejecutar la aplicaci\u00f3n. Se podr\u00e1 definir tambi\u00e9n si desea ser notificado v\u00eda email cuando el estado de sus tareas cambien. Cuando el script est\u00e9 definido se le entrega a slurm para que este se encargue de ejecutarlo.\n\n\nCommandos b\u00e1sicos\n\n\n\n\nscontrol\n - Herramienta par administrar, ver y modificar configuraciones.\n\n\nsinfo\n - Muestra informaci\u00f3n general acerca del sistema de colas.\n\n\nsqueue\n - Muestra informaci\u00f3n detallada de las tareas en las colas.\n\n\nscancel\n - Cancela una tarea de ejecuci\u00f3n.\n\n\nsbatch\n - Ubica el script de ejecuci\u00f3n en la cola definida en el fichero de ejecuci\u00f3n, si no se define una cola slurm ubica la tarea en la cola por defecto.\n\n\nsrun\n - Ejecuta una tarea paralela, de ser necesario crea antes de ejecutar la tarea,  un espacio con los recursos definidos.\n\n\n\n\nDefinir script de ejecuci\u00f3n\n\n\nUn script de ejecuci\u00f3n describe todo lo necesario para ejecutar una tarea(aplicaci\u00f3n,datos de entrada, forma de salida, recursos necesarios, etc  ). El caso simple es cuando la ejecuci\u00f3n de las tareas necesita solo un nodo de ejecuci\u00f3n. \n\n\nPoniendo como caso de ejemplo una aplicaci\u00f3n que tenga los siguientes requerimientos:\n\n\n\n\nEjecutarse en un solo nodo,\n\n\nNo se ejecutar\u00e1 mas de 10 minutos,\n\n\nSe identificar\u00e1 como \"miapp1\",\n\n\nSe quiere ser notificado cada vez que la ejecuci\u00f3n cambie de estado.\n\n\n\n\nSuponiendo que el c\u00f3digo que se desea ejecutar se llama \nmiapp\n, el siguiente script definir\u00eda todos los requerimientos listados arriba y mandar\u00eda a ejecutar \nmiapp\n.\n\n\n#!/bin/bash\n\n# definir n\u00famero de nodos\n#SBATCH --nodes=1\n\n# establecer el tiempo m\u00e1ximo que se desea ejecutar la aplicaci\u00f3n\n#SBATCH --time=00:10:00\n\n# definir el nombre de la ejecuci\u00f3n\n#SBATCH --job-name=miapp1\n\n# establecer ser notificado cada vez que la ejecuci\u00f3n cambie de estado\n#SBATCH --mail-type=ALL\n\n# definir a cual direcci\u00f3n de correo deben llegar las notificaciones\n#SBATCH --mail-user=john.smith@uci.cu\n\n# mandar a ejecutar la aplicaci\u00f3n\nmiapp\n\n\n\n\nEl script comienza con \n#!/bin/bash\n , que indica que el script es script bash de linux.\n\n\nDespu\u00e9s de definir el \nshebang\n siguen un conjunto de lineas iniciadas con \n#SBATCH\n, directivas slurm para definir los recursos computacionales y las configuraciones generales de la ejecuci\u00f3n tales como nombre, etc. Las directivas  \n#SBATCH\n deben ser ubicadas al inicio de la ejecuci\u00f3n antes cualquier otro comando, las directivas definidas despu\u00e9s de alg\u00fan comando son ignoradas. \n\n\nDefinir la cantidad de nodos\n\n\nLa directiva \n#SBATCH --nodes=1\n determina la cantidad de nodos necesarios para la ejecuci\u00f3n, para el ejemplo solo se solicit\u00f3 un nodo. La cantidad de nodos que se soliciten es un tema importante, si se solicitan m\u00e1s nodos de los que realmente se empleen en la ejecuci\u00f3n, los nodos que no se empleen estar\u00e1n reservados para la ejecuci\u00f3n pero no se estar\u00e1n utilizando.\n\n\nDefinir el tiempo m\u00e1ximo de ejecuci\u00f3n\n\n\nLa directiva \n#SBATCH --time=00:10:00\n especifica el tiempo m\u00e1ximo que la aplicaci\u00f3n estar\u00e1 ejecut\u00e1ndose, este tiempo no tiene en cuenta el tiempo que la tarea estar\u00e1 en estado de espera en la cola de ejecuci\u00f3n. El formato del tiempo estar\u00e1 definido por h:m:s y se espera que la ejecuci\u00f3n termine antes de vencerse el tiempo m\u00e1ximo. Cuando el tiempo m\u00e1ximo es alcanzado slurm termina la tarea sin importar el estado de la ejecuci\u00f3n.   \n\n\nDefinir el nombre de la ejecuci\u00f3n\n\n\nLa directiva \n#SBATCH --job-name=miapp1\n define el nombre de la tarea\n\n\nNotificaciones\n\n\nSi la directiva \n#SBATCH --mail-user=john.smith@uci.cu\n es especificada un correo de notificaci\u00f3n es enviado a la direcci\u00f3n solicitada. Para definir en que momento se desea recibir notificaciones se define la directiva \n#SBATCH --mail-type=\ntype\n, donde \n puede ser  \nBEGIN\n, \nEND\n, \nFAIL\n, \nREQUEUE\n o \nALL\n (para cualquier cambio del estado).\n\n\nPor \u00faltimo se especifica las operaciones que se desean ejecutar utilizando comandos linux. La tarea se inicia en la carpeta desde la cual fue enviada a slurm, pero esto puede ser cambiado desde el script, al igual que desde el script se pueden modificar, crear  o eliminar   variables de entorno, as\u00ed como definir los m\u00f3dulos que se desean utilizar.\n\n\nDefinir el n\u00famero de procesos por nodo.\n\n\nSi se desea ejecutar la aplicaci\u00f3n de manera concurrente en m\u00e1s de un nodo y utilizando varios procesos se puede definir la cantidad de tareas que se desean ejecutar por nodos utilizando la directiva \n#SBATCH --ntasks-per-node=n\n, donde n es un n\u00famero entero. \n\n\nEjemplo de ejecuci\u00f3n en multiples nodos\n\n\nSe dese ejecutar una aplicaci\u00f3n utilizando 32 procesadores, en un conjunto de nodos que tienen 16 procesadores cada 1 con los siguientes requerimientos:\n\n\n\n\nEjecutar sobre 32 procesadores,\n\n\nNo se ejecutar\u00e1 mas de 100 horas,\n\n\nSe identificar\u00e1 como \"miapp2\",\n\n\nSe quiere ser notificado cada vez que la ejecuci\u00f3n cambie de estado,\n\n\nTiene dependencia de mpi.\n\n\n\n\n#!/bin/bash\n\n# definir n\u00famero de nodos\n#SBATCH --nodes=1\n\n# Definir el numero de tareas(procesos) a ejecutar en cada nodo.\n#SBATCH --ntasks-per-node=16\n\n\n# establecer el tiempo m\u00e1ximo que se desea ejecutar la aplicaci\u00f3n\n#SBATCH --time=100:00:00\n\n# definir el nombre de la ejecuci\u00f3n\n#SBATCH --job-name=miapp2\n\n# establecer ser notificado cada vez que la ejecuci\u00f3n cambie de estado\n#SBATCH --mail-type=ALL\n\n# definir a cual direcci\u00f3n de correo deben llegar las notificaciones\n#SBATCH --mail-user=john.smith@uci.cu\n\n# mandar a ejecutar la aplicaci\u00f3n\nmpirun $MPI_HOSTS miaap2\n\n\n\n\nEjecutar un script slurm\n\n\nDefinido el script de ejecuci\u00f3n, se enviar\u00e1 a slurm utilizando el comando \nsbatch script_name\n . El sistema de colas devuelve un n\u00famero de identificaci\u00f3n de la tarea en la cola y devuelve el control a la terminal de linux. Por defecto slurm crea ficheros de ejecuci\u00f3n donde se van mostrando los mensajes enviados a la salida est\u00e1ndar del sistema. Una vez se envi\u00e9 el trabajo estar\u00e1 en estado pendiente hasta que los recursos necesarios para la ejecuci\u00f3n est\u00e9n disponibles y se cumplan las reglas de prioridad definidas. \n\n\nMonitorear el estado de las ejecuciones\n\n\nCon el comando \nsqueue\n se  puede ver el estado de la ejecuci\u00f3n. El comando \nsqueue\n muestra la lista de tareas actuales en el estado en el que se encuentran.\n\n\n         JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           173    normal execClus   user99 PD       0:00      3 (Resources)\n\n\n\nLa primera columna muestra el identificador de la tarea,  la segunda columna muestra la cola o partici\u00f3n  donde se est\u00e1 ejecutando la tarea, la tercera columna muestra el  nombre que se especific\u00f3 y la cuarta muestra el propietario de la tarea. La quinta columna muestra el estado de la ejecuci\u00f3n, el estado puede ser (R=ejecutando, PD=pendiente, CA=cancelado, CF=configurando, CG=completando, CD=completo, F=fallido). La sexta columna muestra el tiempo durante el cual se ha estado ejecutando  la tarea. Finalmente se muestra el n\u00famero de nodos pedidos y la lista de nombre de los nodos que est\u00e1n participando en la ejecuci\u00f3n. Si la tarea no se est\u00e1 ejecutando esta columna muestra la causa por el cual no se est\u00e1 ejecutando.\n\n\nEliminar tareas\n\n\nEl comando \nscancel\n elimina las tareas de la cola de ejecuci\u00f3n, sin importar el estado en el que est\u00e9. \nscancel 173\n elimina la tarea con identificador 173. Un usuario solo podr\u00e1 borrar las tareas de su propiedad.\n\n\nEnlaces de inter\u00e9s\n\n\n\n\n\n\nComandos b\u00e1sicos de slurm\n \n\n\n\n\n\n\nQuick start slurm\n\n\n\n\n\n\nslurm", 
            "title": "Ejecutar tareas"
        }, 
        {
            "location": "/comandos/#ejecucion-de-tareas", 
            "text": "El cluster cuenta con  slurm  como planificador de tareas.  El usuario tendr\u00e1 la oportunidad de ejecutar sus tareas en las diferentes colas de ejecuci\u00f3n, en dependencia del tiempo y los recursos necesarios para ejecutar la tarea.", 
            "title": "Ejecuci\u00f3n de tareas"
        }, 
        {
            "location": "/comandos/#introduccion", 
            "text": "Las tareas en el cluster ser\u00e1n atendidas por slurm. Para poder ejecutar una tarea normalmente un usuario debe preparar un script de ejecuci\u00f3n donde define la aplicaci\u00f3n que desea ejecutar, los juegos de entrada, la forma en que obtendr\u00e1 la salida y los recursos que necesita para ejecutar la aplicaci\u00f3n. Se podr\u00e1 definir tambi\u00e9n si desea ser notificado v\u00eda email cuando el estado de sus tareas cambien. Cuando el script est\u00e9 definido se le entrega a slurm para que este se encargue de ejecutarlo.", 
            "title": "Introducci\u00f3n"
        }, 
        {
            "location": "/comandos/#commandos-basicos", 
            "text": "scontrol  - Herramienta par administrar, ver y modificar configuraciones.  sinfo  - Muestra informaci\u00f3n general acerca del sistema de colas.  squeue  - Muestra informaci\u00f3n detallada de las tareas en las colas.  scancel  - Cancela una tarea de ejecuci\u00f3n.  sbatch  - Ubica el script de ejecuci\u00f3n en la cola definida en el fichero de ejecuci\u00f3n, si no se define una cola slurm ubica la tarea en la cola por defecto.  srun  - Ejecuta una tarea paralela, de ser necesario crea antes de ejecutar la tarea,  un espacio con los recursos definidos.", 
            "title": "Commandos b\u00e1sicos"
        }, 
        {
            "location": "/comandos/#definir-script-de-ejecucion", 
            "text": "Un script de ejecuci\u00f3n describe todo lo necesario para ejecutar una tarea(aplicaci\u00f3n,datos de entrada, forma de salida, recursos necesarios, etc  ). El caso simple es cuando la ejecuci\u00f3n de las tareas necesita solo un nodo de ejecuci\u00f3n.   Poniendo como caso de ejemplo una aplicaci\u00f3n que tenga los siguientes requerimientos:   Ejecutarse en un solo nodo,  No se ejecutar\u00e1 mas de 10 minutos,  Se identificar\u00e1 como \"miapp1\",  Se quiere ser notificado cada vez que la ejecuci\u00f3n cambie de estado.   Suponiendo que el c\u00f3digo que se desea ejecutar se llama  miapp , el siguiente script definir\u00eda todos los requerimientos listados arriba y mandar\u00eda a ejecutar  miapp .  #!/bin/bash\n\n# definir n\u00famero de nodos\n#SBATCH --nodes=1\n\n# establecer el tiempo m\u00e1ximo que se desea ejecutar la aplicaci\u00f3n\n#SBATCH --time=00:10:00\n\n# definir el nombre de la ejecuci\u00f3n\n#SBATCH --job-name=miapp1\n\n# establecer ser notificado cada vez que la ejecuci\u00f3n cambie de estado\n#SBATCH --mail-type=ALL\n\n# definir a cual direcci\u00f3n de correo deben llegar las notificaciones\n#SBATCH --mail-user=john.smith@uci.cu\n\n# mandar a ejecutar la aplicaci\u00f3n\nmiapp  El script comienza con  #!/bin/bash  , que indica que el script es script bash de linux.  Despu\u00e9s de definir el  shebang  siguen un conjunto de lineas iniciadas con  #SBATCH , directivas slurm para definir los recursos computacionales y las configuraciones generales de la ejecuci\u00f3n tales como nombre, etc. Las directivas   #SBATCH  deben ser ubicadas al inicio de la ejecuci\u00f3n antes cualquier otro comando, las directivas definidas despu\u00e9s de alg\u00fan comando son ignoradas.", 
            "title": "Definir script de ejecuci\u00f3n"
        }, 
        {
            "location": "/comandos/#definir-la-cantidad-de-nodos", 
            "text": "La directiva  #SBATCH --nodes=1  determina la cantidad de nodos necesarios para la ejecuci\u00f3n, para el ejemplo solo se solicit\u00f3 un nodo. La cantidad de nodos que se soliciten es un tema importante, si se solicitan m\u00e1s nodos de los que realmente se empleen en la ejecuci\u00f3n, los nodos que no se empleen estar\u00e1n reservados para la ejecuci\u00f3n pero no se estar\u00e1n utilizando.", 
            "title": "Definir la cantidad de nodos"
        }, 
        {
            "location": "/comandos/#definir-el-tiempo-maximo-de-ejecucion", 
            "text": "La directiva  #SBATCH --time=00:10:00  especifica el tiempo m\u00e1ximo que la aplicaci\u00f3n estar\u00e1 ejecut\u00e1ndose, este tiempo no tiene en cuenta el tiempo que la tarea estar\u00e1 en estado de espera en la cola de ejecuci\u00f3n. El formato del tiempo estar\u00e1 definido por h:m:s y se espera que la ejecuci\u00f3n termine antes de vencerse el tiempo m\u00e1ximo. Cuando el tiempo m\u00e1ximo es alcanzado slurm termina la tarea sin importar el estado de la ejecuci\u00f3n.", 
            "title": "Definir el tiempo m\u00e1ximo de ejecuci\u00f3n"
        }, 
        {
            "location": "/comandos/#definir-el-nombre-de-la-ejecucion", 
            "text": "La directiva  #SBATCH --job-name=miapp1  define el nombre de la tarea", 
            "title": "Definir el nombre de la ejecuci\u00f3n"
        }, 
        {
            "location": "/comandos/#notificaciones", 
            "text": "Si la directiva  #SBATCH --mail-user=john.smith@uci.cu  es especificada un correo de notificaci\u00f3n es enviado a la direcci\u00f3n solicitada. Para definir en que momento se desea recibir notificaciones se define la directiva  #SBATCH --mail-type= type , donde   puede ser   BEGIN ,  END ,  FAIL ,  REQUEUE  o  ALL  (para cualquier cambio del estado).  Por \u00faltimo se especifica las operaciones que se desean ejecutar utilizando comandos linux. La tarea se inicia en la carpeta desde la cual fue enviada a slurm, pero esto puede ser cambiado desde el script, al igual que desde el script se pueden modificar, crear  o eliminar   variables de entorno, as\u00ed como definir los m\u00f3dulos que se desean utilizar.", 
            "title": "Notificaciones"
        }, 
        {
            "location": "/comandos/#definir-el-numero-de-procesos-por-nodo", 
            "text": "Si se desea ejecutar la aplicaci\u00f3n de manera concurrente en m\u00e1s de un nodo y utilizando varios procesos se puede definir la cantidad de tareas que se desean ejecutar por nodos utilizando la directiva  #SBATCH --ntasks-per-node=n , donde n es un n\u00famero entero.", 
            "title": "Definir el n\u00famero de procesos por nodo."
        }, 
        {
            "location": "/comandos/#ejemplo-de-ejecucion-en-multiples-nodos", 
            "text": "Se dese ejecutar una aplicaci\u00f3n utilizando 32 procesadores, en un conjunto de nodos que tienen 16 procesadores cada 1 con los siguientes requerimientos:   Ejecutar sobre 32 procesadores,  No se ejecutar\u00e1 mas de 100 horas,  Se identificar\u00e1 como \"miapp2\",  Se quiere ser notificado cada vez que la ejecuci\u00f3n cambie de estado,  Tiene dependencia de mpi.   #!/bin/bash\n\n# definir n\u00famero de nodos\n#SBATCH --nodes=1\n\n# Definir el numero de tareas(procesos) a ejecutar en cada nodo.\n#SBATCH --ntasks-per-node=16\n\n\n# establecer el tiempo m\u00e1ximo que se desea ejecutar la aplicaci\u00f3n\n#SBATCH --time=100:00:00\n\n# definir el nombre de la ejecuci\u00f3n\n#SBATCH --job-name=miapp2\n\n# establecer ser notificado cada vez que la ejecuci\u00f3n cambie de estado\n#SBATCH --mail-type=ALL\n\n# definir a cual direcci\u00f3n de correo deben llegar las notificaciones\n#SBATCH --mail-user=john.smith@uci.cu\n\n# mandar a ejecutar la aplicaci\u00f3n\nmpirun $MPI_HOSTS miaap2", 
            "title": "Ejemplo de ejecuci\u00f3n en multiples nodos"
        }, 
        {
            "location": "/comandos/#ejecutar-un-script-slurm", 
            "text": "Definido el script de ejecuci\u00f3n, se enviar\u00e1 a slurm utilizando el comando  sbatch script_name  . El sistema de colas devuelve un n\u00famero de identificaci\u00f3n de la tarea en la cola y devuelve el control a la terminal de linux. Por defecto slurm crea ficheros de ejecuci\u00f3n donde se van mostrando los mensajes enviados a la salida est\u00e1ndar del sistema. Una vez se envi\u00e9 el trabajo estar\u00e1 en estado pendiente hasta que los recursos necesarios para la ejecuci\u00f3n est\u00e9n disponibles y se cumplan las reglas de prioridad definidas.", 
            "title": "Ejecutar un script slurm"
        }, 
        {
            "location": "/comandos/#monitorear-el-estado-de-las-ejecuciones", 
            "text": "Con el comando  squeue  se  puede ver el estado de la ejecuci\u00f3n. El comando  squeue  muestra la lista de tareas actuales en el estado en el que se encuentran.           JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           173    normal execClus   user99 PD       0:00      3 (Resources)  La primera columna muestra el identificador de la tarea,  la segunda columna muestra la cola o partici\u00f3n  donde se est\u00e1 ejecutando la tarea, la tercera columna muestra el  nombre que se especific\u00f3 y la cuarta muestra el propietario de la tarea. La quinta columna muestra el estado de la ejecuci\u00f3n, el estado puede ser (R=ejecutando, PD=pendiente, CA=cancelado, CF=configurando, CG=completando, CD=completo, F=fallido). La sexta columna muestra el tiempo durante el cual se ha estado ejecutando  la tarea. Finalmente se muestra el n\u00famero de nodos pedidos y la lista de nombre de los nodos que est\u00e1n participando en la ejecuci\u00f3n. Si la tarea no se est\u00e1 ejecutando esta columna muestra la causa por el cual no se est\u00e1 ejecutando.", 
            "title": "Monitorear el estado de las ejecuciones"
        }, 
        {
            "location": "/comandos/#eliminar-tareas", 
            "text": "El comando  scancel  elimina las tareas de la cola de ejecuci\u00f3n, sin importar el estado en el que est\u00e9.  scancel 173  elimina la tarea con identificador 173. Un usuario solo podr\u00e1 borrar las tareas de su propiedad.", 
            "title": "Eliminar tareas"
        }, 
        {
            "location": "/comandos/#enlaces-de-interes", 
            "text": "Comandos b\u00e1sicos de slurm      Quick start slurm    slurm", 
            "title": "Enlaces de inter\u00e9s"
        }, 
        {
            "location": "/moduleenv/", 
            "text": "Ambiente \nmodule\n y paquete \nEasyBuild\n\n\nAmbiente \nmodule\n\n\nLa ejecuci\u00f3n de aplicaciones en un ambiente HPC depende de un sin n\u00famero de herramientas de compilaci\u00f3n y ejecuci\u00f3n  en la mayor\u00eda de los casos con diferencias entre las versiones existentes.  En el cluster pueden existir varias versiones de un mismo compilador, por ejemplo, diferentes versiones de \nPython\n o \nGCC\n que a su vez pueden depender de versiones distintas de bibliotecas. \n\n\nUso b\u00e1sico de \nmodule\n\n\nEl cluster tiene instalado un conjunto de paquetes con diferentes versiones que son tratados como m\u00f3dulos. Estos paquetes pueden ser compiladores, interpretes, herramientas bioinform\u00e1ticas o bibliotecas para enumerar algunos. Todos estos m\u00f3dulos son tratados con el comando \nmodule\n. \n\n\nPara ver la lista de paquetes disponibles en el cluster utilice el comando \nmodule av\n.\n\n\n-----/opt/ohpc/pub/moduledeps/gnu-openmpi----\n   scalapack/2.0.2\n\n---- /opt/ohpc/pub/moduledeps/gnu ----\n   numpy/1.11.1    \n   openblas/0.2.19    \n   openmpi/1.10.6 (L)\n\n---- /opt/ohpc/pub/modulefiles ----\n   EasyBuild/3.4.1        \n   cmake/3.9.2        \n   gnu7/7.2.0      \n   llvm4/4.0.1        \n   pmix/1.2.3        \n   valgrind/3.13.0\n   autotools       (L)    \n   gnu/5.4.0   (L)    \n   hwloc/1.11.8    ohpc        (L)    \n   prun/1.2   (L)\n\n  Where:\n   L:  Module is loaded\n\nUse \nmodule spider\n to find all possible modules.\nUse \nmodule keyword key1 key2 ...\n to search for all possible modules matching any of the \nkeys\n.\n\n\n\n\nEste comando muestra la lista de paquetes que pueden ser cargados en el sistema. Algunos paquetes contienen en sus nombres goolf o gompi. Estos est\u00e1n indicando que esos paquetes tienen dependencias con las versiones de goolf o gompi se\u00f1aladas. Las dependencias son mostradas despu\u00e9s del signo \n-\n. En la lista de paquetes tambi\u00e9n se encuentran las versiones disponibles. A la derecha del signo \n/\n se encuentra las versiones de los paquetes que se encuentran y se pueden cargar.\n\n\nPara mostrar los paquetes que est\u00e1n cargados se uiliza el comando \nmodule list\n. \n\n\nmodule list \n\nCurrently Loaded Modules:\n  1) autotools   2) prun/1.2   3) gnu/5.4.0   4) openmpi/1.10.6   5) ohpc\n\n\n\n\nUn m\u00f3dulo es cargado utilizando el comando \nmodule load nombre_modulo\n, donde \nnombre_module\n es el nombre del m\u00f3dulo que se desea cargar. \n\n\nmodule load Beast/1.8.4\nmodule list\n\nCurrently Loaded Modules:\n  1) autotools   \n  2) prun/1.2   \n  3) gnu/5.4.0   \n  4) openmpi/1.10.6   \n  5) ohpc   \n  6) EasyBuild/3.4.1   \n  7) Java/1.8.0_144   \n  8) Beast/1.8.4\n\n\n\n\nEn el caso de que el m\u00f3dulo tenga diferentes versiones se debe especificar la versi\u00f3n deseada. Si no se especifica la versi\u00f3n se carga la versi\u00f3n que ordenada lexicograficamente es la \u00faltima, que normalmente es la versi\u00f3n m\u00e1s reciente.\n\n\nSi se termina de utilizar un paquete el comando   \nmodule unload nombre_modulo\n elimina el paquete de la lista de paquetes cargados. Si se desean eliminar todos los paquetes cargados se utiliza el comando \nmodule purge\n.  Es una buena pr\u00e1ctica utilizar \nmodule purge\n en los scripts de ejecuci\u00f3n antes de cargar los m\u00f3dulos necesarios. Esto evita un conflicto de de versiones. \n\n\nPaquete EasyBuild\n\n\nSeg\u00fan la \ndocumentaci\u00f3n oficial\n \nEasyBuild\n es un \nframework\n para la compilaci\u00f3n e instalaci\u00f3n de aplicaciones y sus dependencias en sistemas HPC de manera eficiente.\n\n\nEl comando b\u00e1sico es \neb\n y para decirle a \nEasyBuild\n que aplicaci\u00f3n utilizar se puede hacer de dos maneras:\n\n\n\n\nMediante un archivo de configuraci\u00f3n \neasyconfig\n.\n\n\nMediante linea de comandos.( Solo se va a explicar la primera ) \n\n\n\n\nLa manera m\u00e1s sencilla es definir un fichero de configuraci\u00f3n donde se definen los pasos y las direcciones de los fuentes que se desean instalar. \neb easyconfig\n busca los c\u00f3digos fuentes  desde una ubicaci\u00f3n local o lo descarga desde uns direcci\u00f3n remota y  ejecuta los pasos que se especifiquen en el fichero \neasyconfig\n. \n\n\n eb Beast-1.8.4.eb --robot\n\n\n\n\nSi es necesario instalar dependencias existe la opci\u00f3n \n--robot\n que busca primero las dependencias y luego procesa la aplicaci\u00f3n objetivo. \n\n\nLuego de  instalar la aplicaci\u00f3n esta podr\u00e1 ser tratada por el paquete \nmodule\n.\n\n\nEn el \nproyecto de easyBuild en GitHub\n hay un conjunto de ficheros easyconfig para la mayor\u00eda de las aplicaciones que se ejecutan hoy en ambientes HPC.\n\n\nEnlaces de inter\u00e9s\n\n\n\n\nDocumentaci\u00f3n EasyBuild\n\n\nman Module\n\n\nDocumentaci\u00f3n module", 
            "title": "Ambiente module/Easybuild"
        }, 
        {
            "location": "/moduleenv/#ambiente-module-y-paquete-easybuild", 
            "text": "", 
            "title": "Ambiente module y paquete EasyBuild"
        }, 
        {
            "location": "/moduleenv/#ambiente-module", 
            "text": "La ejecuci\u00f3n de aplicaciones en un ambiente HPC depende de un sin n\u00famero de herramientas de compilaci\u00f3n y ejecuci\u00f3n  en la mayor\u00eda de los casos con diferencias entre las versiones existentes.  En el cluster pueden existir varias versiones de un mismo compilador, por ejemplo, diferentes versiones de  Python  o  GCC  que a su vez pueden depender de versiones distintas de bibliotecas.", 
            "title": "Ambiente module"
        }, 
        {
            "location": "/moduleenv/#uso-basico-de-module", 
            "text": "El cluster tiene instalado un conjunto de paquetes con diferentes versiones que son tratados como m\u00f3dulos. Estos paquetes pueden ser compiladores, interpretes, herramientas bioinform\u00e1ticas o bibliotecas para enumerar algunos. Todos estos m\u00f3dulos son tratados con el comando  module .   Para ver la lista de paquetes disponibles en el cluster utilice el comando  module av .  -----/opt/ohpc/pub/moduledeps/gnu-openmpi----\n   scalapack/2.0.2\n\n---- /opt/ohpc/pub/moduledeps/gnu ----\n   numpy/1.11.1    \n   openblas/0.2.19    \n   openmpi/1.10.6 (L)\n\n---- /opt/ohpc/pub/modulefiles ----\n   EasyBuild/3.4.1        \n   cmake/3.9.2        \n   gnu7/7.2.0      \n   llvm4/4.0.1        \n   pmix/1.2.3        \n   valgrind/3.13.0\n   autotools       (L)    \n   gnu/5.4.0   (L)    \n   hwloc/1.11.8    ohpc        (L)    \n   prun/1.2   (L)\n\n  Where:\n   L:  Module is loaded\n\nUse  module spider  to find all possible modules.\nUse  module keyword key1 key2 ...  to search for all possible modules matching any of the  keys .  Este comando muestra la lista de paquetes que pueden ser cargados en el sistema. Algunos paquetes contienen en sus nombres goolf o gompi. Estos est\u00e1n indicando que esos paquetes tienen dependencias con las versiones de goolf o gompi se\u00f1aladas. Las dependencias son mostradas despu\u00e9s del signo  - . En la lista de paquetes tambi\u00e9n se encuentran las versiones disponibles. A la derecha del signo  /  se encuentra las versiones de los paquetes que se encuentran y se pueden cargar.  Para mostrar los paquetes que est\u00e1n cargados se uiliza el comando  module list .   module list \n\nCurrently Loaded Modules:\n  1) autotools   2) prun/1.2   3) gnu/5.4.0   4) openmpi/1.10.6   5) ohpc  Un m\u00f3dulo es cargado utilizando el comando  module load nombre_modulo , donde  nombre_module  es el nombre del m\u00f3dulo que se desea cargar.   module load Beast/1.8.4\nmodule list\n\nCurrently Loaded Modules:\n  1) autotools   \n  2) prun/1.2   \n  3) gnu/5.4.0   \n  4) openmpi/1.10.6   \n  5) ohpc   \n  6) EasyBuild/3.4.1   \n  7) Java/1.8.0_144   \n  8) Beast/1.8.4  En el caso de que el m\u00f3dulo tenga diferentes versiones se debe especificar la versi\u00f3n deseada. Si no se especifica la versi\u00f3n se carga la versi\u00f3n que ordenada lexicograficamente es la \u00faltima, que normalmente es la versi\u00f3n m\u00e1s reciente.  Si se termina de utilizar un paquete el comando    module unload nombre_modulo  elimina el paquete de la lista de paquetes cargados. Si se desean eliminar todos los paquetes cargados se utiliza el comando  module purge .  Es una buena pr\u00e1ctica utilizar  module purge  en los scripts de ejecuci\u00f3n antes de cargar los m\u00f3dulos necesarios. Esto evita un conflicto de de versiones.", 
            "title": "Uso b\u00e1sico de module"
        }, 
        {
            "location": "/moduleenv/#paquete-easybuild", 
            "text": "Seg\u00fan la  documentaci\u00f3n oficial   EasyBuild  es un  framework  para la compilaci\u00f3n e instalaci\u00f3n de aplicaciones y sus dependencias en sistemas HPC de manera eficiente.  El comando b\u00e1sico es  eb  y para decirle a  EasyBuild  que aplicaci\u00f3n utilizar se puede hacer de dos maneras:   Mediante un archivo de configuraci\u00f3n  easyconfig .  Mediante linea de comandos.( Solo se va a explicar la primera )    La manera m\u00e1s sencilla es definir un fichero de configuraci\u00f3n donde se definen los pasos y las direcciones de los fuentes que se desean instalar.  eb easyconfig  busca los c\u00f3digos fuentes  desde una ubicaci\u00f3n local o lo descarga desde uns direcci\u00f3n remota y  ejecuta los pasos que se especifiquen en el fichero  easyconfig .    eb Beast-1.8.4.eb --robot  Si es necesario instalar dependencias existe la opci\u00f3n  --robot  que busca primero las dependencias y luego procesa la aplicaci\u00f3n objetivo.   Luego de  instalar la aplicaci\u00f3n esta podr\u00e1 ser tratada por el paquete  module .  En el  proyecto de easyBuild en GitHub  hay un conjunto de ficheros easyconfig para la mayor\u00eda de las aplicaciones que se ejecutan hoy en ambientes HPC.", 
            "title": "Paquete EasyBuild"
        }, 
        {
            "location": "/moduleenv/#enlaces-de-interes", 
            "text": "Documentaci\u00f3n EasyBuild  man Module  Documentaci\u00f3n module", 
            "title": "Enlaces de inter\u00e9s"
        }, 
        {
            "location": "/listadoapps/", 
            "text": "Aplicaciones disponibles\n\n\nEntorno de compilaci\u00f3n:\n\n\n\n\n\n\n\n\nAplicaciones\n\n\nVersi\u00f3n\n\n\nDescripci\u00f3n\n\n\n\n\n\n\n\n\n\n\nGCC/G++/GFORTRAN\n\n\n4.7.2\n\n\nColecci\u00f3n de compiladores GNU.\n\n\n\n\n\n\nGCC/G++/GFORTRAN\n\n\n5.4.0\n\n\nColecci\u00f3n de compiladores GNU.\n\n\n\n\n\n\nGCC/G++/GFORTRAN\n\n\n7.2.0\n\n\nColecci\u00f3n de compiladores GNU.\n\n\n\n\n\n\nJava\n\n\n1.8.0_144\n\n\nPlataforma Java.\n\n\n\n\n\n\nCMAKE\n\n\n2.8.12\n\n\nHerramienta multiplataforma de generaci\u00f3n o automatizaci\u00f3n de c\u00f3digo.\n\n\n\n\n\n\nCMAKE\n\n\n3.9.2\n\n\nHerramienta multiplataforma de generaci\u00f3n o automatizaci\u00f3n de c\u00f3digo.\n\n\n\n\n\n\nPython\n\n\n2.7.5\n\n\nLenguaje de programaci\u00f3n interpretado cuya filosof\u00eda hace hincapi\u00e9 en una sintaxis que favorezca un c\u00f3digo legible.\n\n\n\n\n\n\nPython\n\n\n3.4.6\n\n\nLenguaje de programaci\u00f3n interpretado cuya filosof\u00eda hace hincapi\u00e9 en una sintaxis que favorezca un c\u00f3digo legible.\n\n\n\n\n\n\nAutoconf\n\n\n2.69\n\n\nHarrea mienta para crear shell scripts que configuren autom\u00e1ticamente el c\u00f3digo fuente de un software para adaptarlo a diversos sistemas UNIX.\n\n\n\n\n\n\nAutomake\n\n\n1.15\n\n\nHerramienta de programaci\u00f3n que produce programas makefiles portables para el uso de make usado en la compilaci\u00f3n de software.\n\n\n\n\n\n\nAutotools\n\n\n20150215\n\n\nContenedor de las herramientas de compilaci\u00f3n est\u00e1ndar de GNU: Autoconf, Automake y libtool\n\n\n\n\n\n\nant\n\n\n1.9.6\n\n\nHerramienta multiplataforma de generaci\u00f3n o automatizaci\u00f3n de c\u00f3digo desarrollada en java.\n\n\n\n\n\n\nR\n\n\n3.4.2\n\n\nEntorno y lenguaje de programaci\u00f3n con un enfoque al an\u00e1lisis estad\u00edstico.\n\n\n\n\n\n\nintel\n\n\n2015\n\n\nConjunto de compiladores para los lenguajes C y C++, desarrollado por Intel.\n\n\n\n\n\n\nM4\n\n\n1.4.16\n\n\nMacroprocesador o macro lenguaje de prop\u00f3sito general. Es utilizado para generar el script \"configure\", el cual permite hacer portable para cualquier plataforma los c\u00f3digos fuentes.\n\n\n\n\n\n\nPerl\n\n\n5.16.3\n\n\nLenguaje de programaci\u00f3n interpretado de prop\u00f3sito general.\n\n\n\n\n\n\nPerl\n\n\n5.18.2\n\n\nLenguaje de programaci\u00f3n interpretado de prop\u00f3sito general.\n\n\n\n\n\n\n\n\nEntornos HPC:\n\n\n\n\n\n\n\n\nAplicaciones\n\n\nVersi\u00f3n\n\n\nDescripci\u00f3n\n\n\n\n\n\n\n\n\n\n\nmpich\n\n\n3.3b2\n\n\nImplementaci\u00f3n portable de mpi.\n\n\n\n\n\n\nmpich\n\n\n3.2.1\n\n\nImplementaci\u00f3n portable de mpi.\n\n\n\n\n\n\nOpenMPI\n\n\n1.6.4\n\n\nImplementaci\u00f3n de c\u00f3digo abierto de MPI.\n\n\n\n\n\n\nOpenMPI\n\n\n1.10.6\n\n\nImplementaci\u00f3n de c\u00f3digo abierto de MPI.\n\n\n\n\n\n\nOpenMPI\n\n\n1.10.7\n\n\nImplementaci\u00f3n de c\u00f3digo abierto de MPI.\n\n\n\n\n\n\nMPJ-Express\n\n\n0.44\n\n\nImplementaci\u00f3n de c\u00f3digo abierto para java de MPI.\n\n\n\n\n\n\n\n\nHeramientas matem\u00e1ticas:\n\n\n\n\n\n\n\n\nAplicaciones\n\n\nVersi\u00f3n\n\n\nDescripci\u00f3n\n\n\n\n\n\n\n\n\n\n\nWolfram Mathematica\n\n\n11.2\n\n\nLenguaje de programaci\u00f3n de alto nivel y prop\u00f3sito general desarrollado para hacer matem\u00e1ticas.\n\n\n\n\n\n\ngnuplot\n\n\n4.4.4\n\n\nHerramienta portable para la visualizaci\u00f3n de gr\u00e1ficos.\n\n\n\n\n\n\nOctave\n\n\n4.4.0\n\n\nHerramienta basada en la sintaxis matem\u00e1tica  con funciones para visualizar gr\u00e1ficos.\n\n\n\n\n\n\n\n\nPlataforma de estudios bioinform\u00e1ticos:\n\n\n\n\n\n\n\n\nAplicaciones\n\n\nVersi\u00f3n\n\n\nDescripci\u00f3n\n\n\n\n\n\n\n\n\n\n\nBioPython\n\n\n1.70\n\n\nBiblioteca basada en Python pensada para cuantificar y hacer c\u00e1lculos con datos biol\u00f3gicos.\n\n\n\n\n\n\nnumpy\n\n\n1.13.1\n\n\nBiblioteca de funciones matem\u00e1ticas de alto nivel para operar con vectores o matrices.\n\n\n\n\n\n\npandas\n\n\n0.13.1\n\n\nHerramienta de c\u00f3digo abierto para el an\u00e1lisis de datos basaa en python.\n\n\n\n\n\n\nclustalw-mpi\n\n\n0.13\n\n\nHerramienta para crear alineamiento m\u00faltiple basado en el an\u00e1lisis del alineamiento de secuencias por pares\n\n\n\n\n\n\nMAFFT\n\n\n7.299\n\n\nHerramienta para crear alineamiento m\u00faltiple basado en las transformadas de Fourier.\n\n\n\n\n\n\nMUSCLE\n\n\n3.8.31\n\n\nHerramienta para crear alineamiento m\u00faltiple de nucl\u00e9otidos y prote\u00ednas basado en etapas de optimizaci\u00f3n y refinamiento de los alineamientos.\n\n\n\n\n\n\nprobcons\n\n\nv1_12\n\n\nHerramienta para crear alineamiento m\u00faltiple basado en la combinaci\u00f3n de modelos probabilisticos y t\u00e9cnicas basadas en consistencia.\n\n\n\n\n\n\nGblocks\n\n\n0.91b\n\n\nHerramienta para eliminar regiones divergentes en alineamientos de prote\u00ednas y aminoacidos.\n\n\n\n\n\n\nProtTest\n\n\n3.4.2\n\n\nHerramienta bioinform\u00e1tica para seleccionar el mejor modelo para la sustituci\u00f3n de prote\u00ednas.\n\n\n\n\n\n\njmodeltest\n\n\n2.1.10\n\n\nHerramienta bioinform\u00e1tica para seleccionar el mejor modelo para la sustituci\u00f3n de amino \u00e1cidos.\n\n\n\n\n\n\nPhyML\n\n\n20131016\n\n\nHerramienta bioinform\u00e1tica para estimar la filogenia basada en t\u00e9cnicas de m\u00e1xima verosimilitud.\n\n\n\n\n\n\nMrBayes\n\n\n3.2.6\n\n\nHerramienta bioinform\u00e1tica para estimar la filogenia basada en inferencia bayesiana.\n\n\n\n\n\n\nBeast\n\n\n1.8.4\n\n\nHerramienta bioinform\u00e1tica para estimar la filogenia basada en an\u00e1lisis bayesiano.\n\n\n\n\n\n\n\n\nBibliotecas\n\n\nBibliotecas necesarias para mejorar rendimiento de las aplicaciones y hacer c\u00e1lculos avanzados. \n\n\n\n\n\n\n\n\nboost\n\n\nGSL\n\n\nBLAS\n\n\nLAPACK\n\n\n\n\n\n\n\n\n\n\nMKL\n\n\nSCALAPACK\n\n\nCUBLAS\n\n\nEigen\n\n\n\n\n\n\nFFTW\n\n\nGaussian\n\n\nGLib\n\n\ngzip\n\n\n\n\n\n\nhwloc\n\n\nicc\n\n\niccifort\n\n\nictce\n\n\n\n\n\n\nifort\n\n\nncurses\n\n\nOpenBLAS\n\n\ntcl\n\n\n\n\n\n\ntk\n\n\nvtk\n\n\nzlib", 
            "title": "Aplicaciones disponibles"
        }, 
        {
            "location": "/listadoapps/#aplicaciones-disponibles", 
            "text": "", 
            "title": "Aplicaciones disponibles"
        }, 
        {
            "location": "/listadoapps/#entorno-de-compilacion", 
            "text": "Aplicaciones  Versi\u00f3n  Descripci\u00f3n      GCC/G++/GFORTRAN  4.7.2  Colecci\u00f3n de compiladores GNU.    GCC/G++/GFORTRAN  5.4.0  Colecci\u00f3n de compiladores GNU.    GCC/G++/GFORTRAN  7.2.0  Colecci\u00f3n de compiladores GNU.    Java  1.8.0_144  Plataforma Java.    CMAKE  2.8.12  Herramienta multiplataforma de generaci\u00f3n o automatizaci\u00f3n de c\u00f3digo.    CMAKE  3.9.2  Herramienta multiplataforma de generaci\u00f3n o automatizaci\u00f3n de c\u00f3digo.    Python  2.7.5  Lenguaje de programaci\u00f3n interpretado cuya filosof\u00eda hace hincapi\u00e9 en una sintaxis que favorezca un c\u00f3digo legible.    Python  3.4.6  Lenguaje de programaci\u00f3n interpretado cuya filosof\u00eda hace hincapi\u00e9 en una sintaxis que favorezca un c\u00f3digo legible.    Autoconf  2.69  Harrea mienta para crear shell scripts que configuren autom\u00e1ticamente el c\u00f3digo fuente de un software para adaptarlo a diversos sistemas UNIX.    Automake  1.15  Herramienta de programaci\u00f3n que produce programas makefiles portables para el uso de make usado en la compilaci\u00f3n de software.    Autotools  20150215  Contenedor de las herramientas de compilaci\u00f3n est\u00e1ndar de GNU: Autoconf, Automake y libtool    ant  1.9.6  Herramienta multiplataforma de generaci\u00f3n o automatizaci\u00f3n de c\u00f3digo desarrollada en java.    R  3.4.2  Entorno y lenguaje de programaci\u00f3n con un enfoque al an\u00e1lisis estad\u00edstico.    intel  2015  Conjunto de compiladores para los lenguajes C y C++, desarrollado por Intel.    M4  1.4.16  Macroprocesador o macro lenguaje de prop\u00f3sito general. Es utilizado para generar el script \"configure\", el cual permite hacer portable para cualquier plataforma los c\u00f3digos fuentes.    Perl  5.16.3  Lenguaje de programaci\u00f3n interpretado de prop\u00f3sito general.    Perl  5.18.2  Lenguaje de programaci\u00f3n interpretado de prop\u00f3sito general.", 
            "title": "Entorno de compilaci\u00f3n:"
        }, 
        {
            "location": "/listadoapps/#entornos-hpc", 
            "text": "Aplicaciones  Versi\u00f3n  Descripci\u00f3n      mpich  3.3b2  Implementaci\u00f3n portable de mpi.    mpich  3.2.1  Implementaci\u00f3n portable de mpi.    OpenMPI  1.6.4  Implementaci\u00f3n de c\u00f3digo abierto de MPI.    OpenMPI  1.10.6  Implementaci\u00f3n de c\u00f3digo abierto de MPI.    OpenMPI  1.10.7  Implementaci\u00f3n de c\u00f3digo abierto de MPI.    MPJ-Express  0.44  Implementaci\u00f3n de c\u00f3digo abierto para java de MPI.", 
            "title": "Entornos HPC:"
        }, 
        {
            "location": "/listadoapps/#heramientas-matematicas", 
            "text": "Aplicaciones  Versi\u00f3n  Descripci\u00f3n      Wolfram Mathematica  11.2  Lenguaje de programaci\u00f3n de alto nivel y prop\u00f3sito general desarrollado para hacer matem\u00e1ticas.    gnuplot  4.4.4  Herramienta portable para la visualizaci\u00f3n de gr\u00e1ficos.    Octave  4.4.0  Herramienta basada en la sintaxis matem\u00e1tica  con funciones para visualizar gr\u00e1ficos.", 
            "title": "Heramientas matem\u00e1ticas:"
        }, 
        {
            "location": "/listadoapps/#plataforma-de-estudios-bioinformaticos", 
            "text": "Aplicaciones  Versi\u00f3n  Descripci\u00f3n      BioPython  1.70  Biblioteca basada en Python pensada para cuantificar y hacer c\u00e1lculos con datos biol\u00f3gicos.    numpy  1.13.1  Biblioteca de funciones matem\u00e1ticas de alto nivel para operar con vectores o matrices.    pandas  0.13.1  Herramienta de c\u00f3digo abierto para el an\u00e1lisis de datos basaa en python.    clustalw-mpi  0.13  Herramienta para crear alineamiento m\u00faltiple basado en el an\u00e1lisis del alineamiento de secuencias por pares    MAFFT  7.299  Herramienta para crear alineamiento m\u00faltiple basado en las transformadas de Fourier.    MUSCLE  3.8.31  Herramienta para crear alineamiento m\u00faltiple de nucl\u00e9otidos y prote\u00ednas basado en etapas de optimizaci\u00f3n y refinamiento de los alineamientos.    probcons  v1_12  Herramienta para crear alineamiento m\u00faltiple basado en la combinaci\u00f3n de modelos probabilisticos y t\u00e9cnicas basadas en consistencia.    Gblocks  0.91b  Herramienta para eliminar regiones divergentes en alineamientos de prote\u00ednas y aminoacidos.    ProtTest  3.4.2  Herramienta bioinform\u00e1tica para seleccionar el mejor modelo para la sustituci\u00f3n de prote\u00ednas.    jmodeltest  2.1.10  Herramienta bioinform\u00e1tica para seleccionar el mejor modelo para la sustituci\u00f3n de amino \u00e1cidos.    PhyML  20131016  Herramienta bioinform\u00e1tica para estimar la filogenia basada en t\u00e9cnicas de m\u00e1xima verosimilitud.    MrBayes  3.2.6  Herramienta bioinform\u00e1tica para estimar la filogenia basada en inferencia bayesiana.    Beast  1.8.4  Herramienta bioinform\u00e1tica para estimar la filogenia basada en an\u00e1lisis bayesiano.", 
            "title": "Plataforma de estudios bioinform\u00e1ticos:"
        }, 
        {
            "location": "/listadoapps/#bibliotecas", 
            "text": "Bibliotecas necesarias para mejorar rendimiento de las aplicaciones y hacer c\u00e1lculos avanzados.      boost  GSL  BLAS  LAPACK      MKL  SCALAPACK  CUBLAS  Eigen    FFTW  Gaussian  GLib  gzip    hwloc  icc  iccifort  ictce    ifort  ncurses  OpenBLAS  tcl    tk  vtk  zlib", 
            "title": "Bibliotecas"
        }, 
        {
            "location": "/harddesc/", 
            "text": "Aqui se describe el hardware", 
            "title": "Descripci\u00f3n de hardware"
        }, 
        {
            "location": "/harddesc/#aqui-se-describe-el-hardware", 
            "text": "", 
            "title": "Aqui se describe el hardware"
        }
    ]
}